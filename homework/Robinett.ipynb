{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Week 3: Fitting\n",
    "\n",
    "In many different cases, we might have a model for how a system works, and want to fit that model to a set of observations. \n",
    "\n",
    "We're going to investigate a paper using a classic model of multivalent binding to [examine interaction of IgG antibodies with the immune system](https://doi.org/10.1016/j.cels.2018.05.018). Identifying whether and how this model fits has led to a better understanding of how our immune system recognizes diseased cells, and how to design antibodies with optimized responses."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.special import binom\n",
    "from scipy.optimize import brentq\n",
    "\n",
    "np.seterr(over='raise')\n",
    "\n",
    "def bindingModel(Rtot, Ka, v, L0):\n",
    "    '''\n",
    "    Returns the number of mutlivalent ligand bound to a cell with Rtot\n",
    "    receptors, granted each epitope of the ligand binds to the receptor\n",
    "    kind in question with association constant Ka and cross-links with\n",
    "    other receptors with crosslinking constant Kx. All eq derived from\n",
    "    Stone et al. (2001).\n",
    "\n",
    "    Note that this function only takes a single condition at once. All\n",
    "    arguments should be scalars (not vectors)!\n",
    "    '''\n",
    "    v = np.int_(v)\n",
    "    Kx = np.power(10.0, -12.25)\n",
    "    \n",
    "    # Mass balance for receptor species, to identify the amount of free receptor\n",
    "    diffFunAnon = lambda x: Rtot-x*(1+v*L0*(Ka)*(1+Kx*x)**(v-1))\n",
    "    \n",
    "    ## Solve Req by calling least_squares\n",
    "    Req, lsq = brentq(diffFunAnon, 0.0, Rtot, full_output=True)\n",
    "    if lsq.converged is False:\n",
    "        print(lsq)\n",
    "        raise RuntimeError(\"Failure in solving for Req.\")\n",
    "    \n",
    "    # Calculate vieq from equation 1\n",
    "    vieq = L0*Req*binom(v, np.arange(1, v + 1))*np.power(Kx*Req, np.arange(v))*Ka\n",
    "    return np.sum(vieq)\n",
    "\n",
    "\n",
    "# L0 for each TNP-BSA\n",
    "# Define concentrations of TNP-4-BSA and TNP-26-BSA, respectively\n",
    "tnpbsaL0 = np.array([1/67122,1/70928])*1e-3*5\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### (1) Load the data (`robinett.csv`, from Fig. 1). Decide how to account for the control conditions. Plot the data and explore the relationship you see with affinity and valency (see Fig. 1C/D/E for ideas)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Answer"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### (2) To fit the model, we'll first need a function that takes the unknown parameters (Rtot, scaling), uses them to run the model for each condition, scales them to the units of the actual measurements (fluorescence), thus finding the predictions for each condition.\n",
    "\n",
    "Use the fit parameters shown in Fig. 2 and overlay with the measurements to ensure your function is roughly working. The scaling to fluorescence units for each valency should themselves be unknown parameters."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Answer"
   ],
   "outputs": [],
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### (3) Now use `scipy.optimize.least_squares` to find the least squares solution."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Answer"
   ],
   "outputs": [],
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### (4) Using leave-one-out crossvalidation, does this model predict the data? Plot the measured vs. predicted data."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Answer"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### (5) Using bootstrap estimation, plot the confidence interval of the model predictions along with the data points.\n",
    "\"Confidence interval\" does not have a precise definition. For example, you could show the interval over which 50% of the bootstrap samples fall (25th to 75th quantile)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Answer"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### (6) You may find that a subset of points are predicted more poorly than the others. Which are those? What could be wrong about these data points leading to the poor prediction, assuming that the model and binding measurements are true and accurate?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Answer."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### (7) Now, we will perform a local sensitivity analysis to look at the dependence of the model results on each parameter. Vary each parameter up and down by 10-fold **while holding the others constant**, and plot the sum of squared error. Which parameter influences the fit the most? Which one the least?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Answer"
   ],
   "outputs": [],
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### (8) While easier to perform, a local sensitivity analysis ignores codependency between the parameters. Do you anticipate your predictions of the parameter values will be more or less specified with a global analysis?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Answer."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### (9) Now, vary each parameter from the optimal solution, *allowing the other parameters to vary*. Was your prediction true? How are the other parameters varying when the scaling factor increases?\n",
    "\n",
    "Hint: The easiest way to do this is mess with the bounds of the least squares solver."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Answer"
   ],
   "outputs": [],
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### (10) Using the model, go back to one or two of the data points that are poorly predicted. Use the model to provide a new estimate of the input parameter you identified as faulty. How could you estimate the uncertainty in this inference (do not have to implement this latter part)?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Answer"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.7 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "nteract": {
   "version": "0.6.2"
  },
  "interpreter": {
   "hash": "4e5561d61fbbe62c54e6e1d2267cf075ed880fc70d78026b66400a8e2e4d547e"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}